/*
 * This Scala source file was generated by the Gradle 'init' task.
 */
package com.npg.skalator

import org.apache.spark.sql.SparkSession

object App {

  def main(args: Array[String]): Unit = {
    val ss = SparkSession
      .builder
      .appName("Spark Kafka Consumer n_n)")
      .getOrCreate()

    val df = ss
      .read
      .format("kafka")
      .option("kafka.bootstrap.servers", "klooster-03-w-0:9092")
      .option("subscribe", "test")
      .option("enable.auto.commit","true")
      .load()
    df.printSchema()

    val df2 = df.selectExpr("CAST(key as STRING)", "CAST(value as STRING)", "topic")
    val output_path = "gs://dataproc-staging-sa-east1-664534573047-ccfoqrdc/test/out"
    df2.rdd.saveAsTextFile(output_path)

  }

  def greeting(): String = "Hello, world!"

}
